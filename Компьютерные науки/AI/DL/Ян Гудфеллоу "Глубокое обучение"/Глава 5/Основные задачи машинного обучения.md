Задачи машинного обучения обычно описываются в терминах того, как система машинного обучения должна обрабатывать **пример**. **Примером** является набор **признаков**, полученных в результате количественного измерения некоторого объекта или события, которые система должна обрабатывать. Как правило, пример представляется в виде вектора $x∊R^{n}$, каждый элемент которого — признак.

Рассмотрим наиболее типичные задачи, которые можно решить при помощи алгоритмов машинного обучения.
### **Классификация.** 
В задачах этого типа программа должна ответить, какой из $k$ категорий принадлежит некоторый пример. Для решения этой задачи алгоритм обучения обычно просят породить функцию $f:\space R^{n}\to\{1,\dots,k\}$. Если $y=f(x)$, то модель относит входной пример, описываемый вектором $x$, к категории с числовым кодом $y$. Существует и другие варианты задачи классификации, например когда $f$ — распределение вероятности принадлежности к классам.
**Пример:** На вход поступает изображение 100x100 в оттенках серого, на котором изображено число от 0 до 10. Каждый пиксель можно представить некоторым действительным числом в диапазоне от 0 до 1, где число отражает яркость пикселя. Тогда входной образ принадлежит пространству $R^{10000}$. При подаче этого образа обученной функции мы получим в результате число от 0 до 10, которое как раз и отражает предсказанное моделью число.
### **Классификация при отсутствии неоторых данных.** 
Классификация осложняется, если нет гарантии, что программа получает во входном векторе результаты всех измерений. Чтобы решить задачу классификации, алгоритм обучения должен определить всего одну функцию, отображающую входной вектор на код категории. Но если часть входных данных отсутствует, то алгоритм должен обучить набор функций. Каждая из функций соответствует классификаци входного образа $x$ в условиях отсутствия различного подмножества данных. Один из способов эффективно определить такое большое множество функций — обучить распределение вероятности всех релевантных величин, а затем решать задачу классификации, вычисляя маргинальные распределения отсутствующих величин. Если на вход подается $n$ величин, то существует $2^{n}$ различных функций классификации для каждого возможного набора отсутствующих данных, однако программе нужно обучить только одну функцию, описывающую совместное распределение вероятности.
**Пример:** Произошло преступление. На месте происшествия обнаружены 2 улики $x_{1}$ и $x_{2}$. Есть два подозреваемых $y_{1}$ и $y_{2}$, при чем для первого подозреваемого отсутствует улика $x_{3}$, а для второго подозреваемого — $x_{4}$. Цель: узнать наиболее вероятного преступника.
### **Регрессия.** 
В этой задаче программа должна предсказать числовое значение по входным данным. Для ее решения алгоритм обучения просят породить функцию $f:\space R^{n}\to R$. Регрессия отличается от классификации форматом выхода.
**Пример:** Прогнозирование стоимости ценностной бумаги.
### **Транскрипция.** 
В задачах такого типа системе машинного обучения предлагается проанализировать неструктурированное представление некоторых данных и преобразовать его в дискретную текстовую форму.
**Пример:** Программа распознования текста получает фотографию с текстом, следовательно она должна вернуть текст в виде последовательности символов.
### **Машинный перевод**. 
В этой задаче входные данные — последовательность символов на одном языке, а программа должна преобразовать ее в последовательность символов на другом языке
**Пример:** Перевод с английского языка на французский.
### **Структурный вывод.** 
Под структурным выводом понимается любая задача, в которой на выходе порождается вектор (или иная структура, содержащая несколько значений), между элементами которого существуют важные связи. Это широкая категория, в которую, в частности, входят задачи транскрипции и машинного перевода. Еще одна задача — грамматический разбор, т.е. преобразование предложения на естественном языке в дерево, описывающее его грамматическую структуру; узлы такого дерева снабжены метками "глагол", "существительное", "наречие" и т.д. Можно также рассмотреть пиксельную сегментацию изображения, когда программа должна отнести каждый пиксель к определенной категории. 
Формат вывода не всегда так точно повторяет формат ввода, как в задачах, сводящихся к аннотированию. Название "структурный вывод" отражает тот факт, что программа должна вывести несколько тесно связанных между собой значений. Так, слова, порождаемые программой подписывания изображений, должны образовывать допустимое предложение.
### **Обнаружение аномалий**.
В этой задаче программа анализирует множество событий или объектов и помечает некоторые из них как нетипичные. 
**Пример:** Обнаружение мошеничества с кредитными картами. Благодаря моделированию покупательских привычек компания-эмитент кредитных карт может обнаружить аномальное использование карты. Покупки человека, укравшего вашу карту или информацию о ней, зачастую характеризуются не таким распределением вероятности, как ваши. Обнаружив аномальную покупку, компания смоэет предотварить мошеничество, заблокировав счет.
### Синтез и выборка.
В задачах этого типа алгоритм машинного обучения должен генерировать новые примеры, похожие на обучающие данные. Синтез и выборка методами машинного обучения полезны в мультимедийных приложениях, когда генерирование больших объемов данных обходится дорого, скучно или занимает слишком много времени. В некоторых случаях мы хотим, чтобы процедура выборки или синтеза генерировала определенный вывод по заданному входу. Например, в задачае синтеза речи программе передается написанная фраза, а она должна выдать аудиосигнал, содержащий ее же в произнесенном виде. Это разновидность структурного вывода с дополнительной особенностью: для заданного входа не существует единного правильного выхода, мы специально допускаем большую вариативность выхода, чтобы речевой сигнал звучал естественно и реалистично.
### Подстановка отсутствующих значений.
В этом случае алгоритму машинного обучения предъявляется новый пример $x ∊ R^{n}$, в котором некоторые элементы $x$ отсутствуют. Алгоритм должен спрогнозировать значения отсутствующих элементов.
### Шумоподавление.
В этой задаче алгоритму машинного обучения предъявляется искаженный помехами пример $\tilde{x}∊R^{n}$, полученный из чистого примера $x∊R^{n}$ в результате неизвестного процесса искажения. Алгоритм должен восстановить чистый пример $x$ по искаженному $\tilde{x}$ или, в более общем случае, вернуть условное распределение вероятности $p(x|\tilde{x})$.
### Оценка функции вероятности или функции плотности вероятности.
В задаче оценки плотности алгоритм должен обучить функцию $p_{model}:\space R^{n} \to R$, где $p_{model}(x)$ интерпретируется как функция плотности вероятности (если $x$ — непрерывная случайная величина) или как функция вероятности (в дискретном случае) в пространстве, из которого были взяты примеры. Чтобы решить эту задачу хорошо, алгоритм должен выявить структуру предъявленных данных. Он должен понять, где примеры расположены тесно, а где их появление маловероятно. Для большинства описанных выше задач требуется, чтобы алгоритм хотя бы неявно уловил структуру распределения вероятности. В задаче оценки плотности это распределение должно быть определено явно. В принципе, найденное распределение можно использовать и для решения других задач.
