**Обобщение** — это способность модели правильно работать на ранее не предъявлявшихся данных для обучения.
Обычно при обучении модели мы имеем доступ к обучающему набору: можем вычислить некоторую меру ошибки на обучающем наборе, которая называется **ошибкой обучения**, и постараться минимизировать её. Но [[Определение машинного обучения|машинное обучение]] отличается от обычной минимизации тем, что мы также хотим уменьшить **ошибку обобщения (ошибку тестирования)**.
**Ошибка обобщения** — это математическое ожидание ошибки на новых входных данных. Здесь математическое ожидание вычисляется по возможным входным данным, выбираемым из распределения, которое, как мы думаем, может встретиться на практике.
Как правило, для оценки ошибки обобщения модели измеряется ее качество на тестовом наборе данных, отдельном от обучающего набора.
Обучающий и тестовый наборы генерируются из распределения вероятности тестовых наборов **процессом генерации данных**. Обычно считаются справедливыми предположения, в совокупности называемые **i.i.d. (independent and identically-distributed)**, а именно: примеры в каждом наборе независимы и оба набора одинаково распределены, т.е. выбираются из одного и того же распределения вероятности. Это общее распределение называется **порождающим распределением** и обозначается $p_{data}$.
Для фиксированного значения $w$ ошибки на обучающем и тестовом наборах одинаковы, но так как мы сначала используем обучающий набор для минимизации ошибки, а потом выбираем тестовый набор, то соответственно тестовая ошибка будет больше или равна ошибки обучения.
Существует два фактора, определяющих качество машинного обучения:
1) Величина ошибки обучения.
2) Разница между ошибками обучения и тестирования.
Эти факторы соответствуют двум центральным проблемами машинного обучения: переобучение и недообучение.
**Переобучение** — это результат машинного обучения, когда разница между ошибкой обучения и ошибкой тестирования слишком большая.
**Недообучение** — это результат машинного обучения, когда модель не может адекватно уловить признаки в обучающей выборки, в следствие чего ошибка обучения остается слишком большой и не подлежит минимизации.
Управлять склонностью модели к переобучению и недообучению можно при помощи **емкости**.
**Емкость** — это характеристика модели, обозначающая насколько сложные функции она способна аппроксимировать. Модели малой емкости склонны к недообучению, а модели высокой емкости — к переобучению. Управлять емкостью модели можно при помощи **пространства гипотез**.
**Пространство гипотез** — это множество функций (гипотез), которые модель может рассматривать в качестве потеницального решения. Чем больше пространство гипотез, тем выше емкость и наоборот соответственно.
**Пример:**
Рассмотрим задачу регрессии (полиномиальная регрессия второй степени). Возьмем три пространства гипотез:
3) Функции вида $wx + b$
4) Квадратичные функции вида $w_{1}x^{2} + w_{2}x + c$
5) Многочлен девятой степени вида $b+\sum_{i=1}^{9}w_{i}x^{i}$
Модель с первым пространством гипотез никогда не сможет точно аппроксимировать функцию на заданном интервале, что в итоге приведет к недообучению, а модель с третьим пространством гипотез может идеально аппроксимировать функцию на заданном интервале в обучающей выборке, но на теством наборе может сильно ошибаться, что является переобучением. Оптимальным вариантом является второе пространство гипотез.![[Пространства гипотез.png]]
Мы описали лишь один из способов изменения емкости модели — модификация числа признаков с одновременным добавлением параметров, ассоциированных с этими признакими, но существует множество других способов настройки емкости.
Модель задает семейство функций, из которого алгоритм обучения может выбирать в процессе варьирования параметров. Это называется **репрезентативной емкостью**. Поиск наилучшей функции из семейста функций — это трудная задача оптимизации, и в общем случае модель находит не самую лучшую функцию, а лишь такую, которая существенно уменьшает ошибку обучения. Всвязи с различными ограничениями, в том числе несовершенство алгоритма обучения, можно утверждать, что **эффективная емкость** алгоритма может быть меньше репрезентативной емкости.
Теория статистического обучения предлагает различные способы количественного выражения емкости модели. Самый известных из них — **размерность Вапника-Червоненикса**, или **VC-размерность**, измеряющая емкость бинарного классификатора. VC-размерность определяется как наибольшое возможное значение $m$ — такое, что существует обучающий набор $m$ разных точек $x$, которые классификатор может пометить произвольным образом.
Согласно этой теории расхождение между ошибкой обучения и ошибкой обобщения ограничено сверху величиной, которая растет с ростом емкости модели, но убывает по мере увеличения количества обучающих примеров.
В типичном случае ошибка обучения убывает, асимптотически приближаясь к минимально возможной ошибке с ростом емкости модели (в предположении, что у меры ошибки есть минимальное значение). Типичная ошибка обобщения имеет форму U-образной кривой:
![[Связь между емкостью и ошибкой.png]]
**Баейсовская ошибка** — это минимально возможная ошибка классификации идеального классификатора при известных вероятностях классов.
Ошибки обучения и обобщения могут варьироваться в зависимости от размера обучающего набор. Ожидаемая ошибка обобщения никогда не может увеличиться с ростом количества обучающих примеров.
Для непараметрических моделей увеличение объема данных приводит к лучшему обобщению до тех пор, пока не будет достигнута наименьшая возможная ошибка.
Любая фиксированная параметрическая модель емкостью ниже оптимально асимптотически приближается к значению ошибки, больше байесовской.
Может случиться и так, что емкость модели оптимальна, и тем не менее существует большой разрыв между ошибками обучения и обобщения. В такой ситуации разрыв, возможно, удастся сократить, увеличив число обучающих примеров.
![[Влияние размера обучающего набора данных на ошибки обучения и тестирования, а также на оптимальную емкость модели.png]]