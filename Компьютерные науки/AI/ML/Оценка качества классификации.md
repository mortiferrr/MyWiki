Оценить качество [[Классификация|таких классификаторов]] можно при помощи **таблиц сопряженности (или матриц неточности)**. Каждая строка этой таблицы соответствует фактическим классам из тестового набора, каждый столбец — предсказанным моделью классам. Последние столбец и строка содержат **маргиналы** — то есть суммы в соответствующем столбце или строке. Маргиналы очень полезны для оценки **статистической значимости**.
![[Таблицы сопряженности.png]]
По таблице сопряженности мы можем выделить ряд показателей качества. Одним из них является **верность**, то есть доля правильно классифицированных примеров тестовых примеров, которая определяется следующей формулой:
$$
acc = \frac{1}{|Te|} * \sum_{x∈Te} I[\hat{c}(x)=c(x)]
$$
Соответственно для нашей таблицы слева верность для положительного класса составляет 0.7 или же 70%, а для таблицы справа всего 0.5 или же 50%. Противоположным верности показателем качества является **частота ошибок**, т.е. доля неправильно классифицированных тестовых примеров. Она, соответственно, равна 0.3 и 0.5. Сумма частоты ошибок и верности, очевидно, равна единице.
Верность на тестовом наборе можно рассматривать как **оценку вероятности** того, что произвольный объект $x∈\mathcal{X}$ классифицирован правильно, точнее это оценка вероятности:
$$P_{\mathcal{X}}(\hat{c}(x)=c(x))$$
Часто бывает удобно, если не сказать — необходимо, различать качество классификации для отдельных классов. Для этого вводится отдельная треминология — **ложноотрицательные результаты** (неправильно классифицированные положительные объекты) и **ложноположительные результаты** (неправильно классифицированные отрицательные объекты).
**Частотой истинно положительных (отрицательных) результатов** называется доля правильно классифицированных положительных (отрицательных) объектов. Такая частота определяется по формуле:
$$
tpr = \frac{\sum_{x∈Te}I(\hat{c}(x)=c(x)=⊕or⊖)}{\sum_{x∈Te}c(x)=⊕ or ⊖}
$$
Также можно говорить о частотах ошибок на уровне класса, то есть об **частоте ложноположительного (ложноотрицательного) результата**. Частоту ложноположительных результатов также можно называть **частотой ложных тревог**. Чтобы найти эту частоту — нужно поделить соответствующее число на побочной диагонали на соответствующих маргинал в последней строке.
Из таблицы 2.2 выше можем рассчитать:
1) **Частота истинно положительных результатов:** 0.6 (60%) слева и 0.4 (40%) справа.
2) **Частота истинно отрицательных результатов:** 0.8 (80%) слева и 0.6 (60%) справа.
3) **Частота ложноположительных результатов:** 0.2 (20%) слева и 0.4 (40%) справа.
4) **Частота ложноотрицательных результатов:** 0.4 (40%) слева и 0.6 (60%) справа.
Если тестовый набор содержит равное количество положительных и отрицательных примеров, то верность (или частота ошибок) равна среднему арифметическому частот истинно положительных и истинно отрицательных результатов (или же ложноположительных и ложноотрицательных соответственно).
В общем же случае нужно искать не среднее арифметическое, а взвешенное среднее, в котором веса пропорциональны числу положительных и отрицательных объектов в тестовом наборе.
![[Верность как среднее взвешенное.png]]
Судя по формуле 2.3 можно утверждать, что для достижения большей верности нужно больше внимания уделять **мажоритарному классу**, особенно если распределение объектов по классам не сбалансировано. Но часто бывает так, что наиболеее интересен **миноритарный класс**. 
**Рассмотрим пример:** мы посылаем интернет-поисковику запрос, который должен найти релевантную страницу (всего она одна на тысячу нерелевантных). Рассмотрим также "упрямый" поисковик которые не возвращает ничего, то есть все страницы он классифицирует как нерелевантные. Следовательно, частота истинно положительных результатов 0%, а частота истинно отрицательных 100%. Верность модели очень высокая ($\frac{999}{100}=0.999(99.9\%)$). Но у сколько-нибудь полезной поисковой системы частота положительных результатов (без разницы истинных или ложных) должна быть гораздо выше, а это обычно сопровождается соответственным уменьшением частоты истинно отрицательных результатов (и, следовательно, верности классификации). В этом случае верность не играет особой роли.
Если интересен миноритарный класс, и он очень мал, то оптимизация верности и качества классификаци мажоритарного класса — это не то, что нужно. В таком случае вводится понятие **точность**.
**Точность** — это доля истинно положительных результатов во множесте предсказанных положительных результатов.
В примере 2.1 точность равна $\frac{60}{70}=0.857(85,7\%)$. В примере "упрямого" поисковика частота истинно положительных результатов (**полнота**) равна 0 и точность равна 0, что и показывает проблему данного поисковика.
![[Показатели качества бинарного классификатора.png]]