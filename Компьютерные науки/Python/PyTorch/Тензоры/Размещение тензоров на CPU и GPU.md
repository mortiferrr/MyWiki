Если компьютер использует видеокарту NVidia с поддержкой CUDA, то рекомендуется использовать именно её для машинного обучения, так как на ней вычисления происходят гораздо быстрее, чем на центральном процессоре.
Чтобы проверить поддерживает ли PyTorch CUDA нужно использовать комаду **torch.cuda_is_available()**, которая возвращает True, если поддерживает, или False, если не поддерживает.
```Python
# Пример универсальной переменной устройства
device = torch.device('cuda' if torch.cuda_is_available() else 'cpu')
```
По умолчанию все [[Создание и устройство тензоров в PyTorch|тензоры]] располагаются на CPU. При инициализации тензора можно выбрать устройство, на котором он будет храниться, только для метода tensor():
```Python
device = torch.device('cuda' if torch.cuda_is_available() else 'cpu')
w_out = torch.tensor([-1, 1, 0.5], device=device)
```
Чтобы узнать на каком устройстве располагается тензор можно воспользоваться методом **get_device()**, который возвращает -1, если тензор расположен на CPU, и другие числа (неотрицательные) в противном случае.
Чтобы переместить тензор на другое устройство можно воспользоваться методом **to(),** в который мы передаем устройство. Метод возвращает **копию** тензора, к которому применяется, поэтому необходимо выполнить операцию присвоения, чтобы зафиксировать результат:
```Python
device = torch.device('cuda' if torch.cuda_is_available() else 'cpu')
w_out = torch.FloatTensor([-1, 1, 0.5])
w_out = w_out.to(device)
```
Также можно использовать методы **cuda()** и **cpu()**, который переносят тензоры на CUDA и CPU соответственно.
```Python
device = torch.device('cuda' if torch.cuda_is_available() else 'cpu')
w_out = torch.FloatTensor([-1, 1, 0.5])
w_out = w_out.cuda() # w_out теперь на CUDA
w_out = w_out.cpu() # w_out теперь на CPU
```
Метод **cuda()** следует использовать с осторожностью, так как если компьютер не поддерживает CUDA, то произойдет ошибка, но на компьютере всегда есть CPU, поэтому использование метода **cpu()** предпочтительнее, ибо он наглядно показывает куда переносится тензор.
**Примечание:** Если тензоры расположены на разных устройствах, то при попытке выполнить различные операции, которые используют эти тензоры, возникнет ошибка.

Генераторы псевдослучайных чисел на CPU и CUDA работают по-разному. Чтобы задать зерно генерации для графического процесса следует воспользоваться функцией **torch.cuda.manual_seed(<датчик>)** или **torch.cuda.manual_seed_all(<датчик>)**, которая устанавливает датчик псевдослучайных чисел для всех графических процессоров. Но на CUDA даже при установке зерна псевдослучайных чисел они все равно при каждом запуске будут генерироваться по-разному, что связано со стохастичной работой GPU для ускорения вычислений. Рассмотрим на примере как от этого избавиться:
```Python
torch.cuda.manual_seed_all(123)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
```
**Примечание:** Использовать только для отладки, ибо в противном случае обучение будет происходить медленнее.

#CS #Python #PyTorch #Тензоры #CPU #CUDA